name: Full historical scrape

on:
  workflow_dispatch:
    inputs:
      year:
        description: "Årstall for fullscrape (f.eks. 2009)"
        required: true
        type: string

      start_page:
        description: "Start page (f.eks. 3475)"
        required: true
        type: string

      max_pages:
        description: "Max pages (f.eks. 3505)"
        required: true
        type: string

      h1_start:
        description: "Startdato H1 (DD.MM.YYYY)"
        required: true
        type: string

      h1_end:
        description: "Sluttdato H1 (DD.MM.YYYY)"
        required: true
        type: string

      h2_start:
        description: "Startdato H2 (DD.MM.YYYY)"
        required: true
        type: string

      h2_end:
        description: "Sluttdato H2 (DD.MM.YYYY)"
        required: true
        type: string

permissions:
  contents: write

concurrency:
  group: postliste-scraping
  cancel-in-progress: false

jobs:

  setup_environment:
    runs-on: ubuntu-latest

    outputs:
      config_path: ${{ steps.write_config.outputs.config_path }}

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          ref: main

      - name: Sett opp Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Installer Playwright + dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4
          playwright install chromium
          sudo apt-get update
          sudo apt-get install -y \
            libnss3 \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libcups2 \
            libdrm2 \
            libxkbcommon0 \
            libxcomposite1 \
            libxdamage1 \
            libxfixes3 \
            libxrandr2 \
            libgbm1 \
            libasound2t64

      - name: Skriv config_fullscrape.json
        id: write_config
        run: |
          mkdir -p src/config
          CONFIG_PATH="src/config/config_fullscrape.json"

          {
            echo "{"
            echo "  \"start_page\": ${{ github.event.inputs.start_page }},"
            echo "  \"max_pages\": ${{ github.event.inputs.max_pages }},"
            echo "  \"per_page\": 100"
            echo "}"
          } > $CONFIG_PATH

          echo "config_path=$CONFIG_PATH" >> $GITHUB_OUTPUT

          echo "=== INNHOLD I config_fullscrape.json ==="
          cat $CONFIG_PATH


  scrape_H1:
    runs-on: ubuntu-latest
    needs: setup_environment

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          ref: main

      - name: Kjør H1-scrape
        working-directory: src/scrapers
        run: |
          echo "=== STARTER FULLSCRAPE H1 ==="
          python scraper_dates.py \
            --config ../config/config_fullscrape.json \
            "${{ github.event.inputs.h1_start }}" \
            "${{ github.event.inputs.h1_end }}"

      - name: Arkiver H1-resultat
        run: |
          mkdir -p data/archive
          cp data/postliste.json \
            "data/archive/postliste_${{ github.event.inputs.year }}_H1.json"

      - name: Commit og push H1
        run: |
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          git add data/archive/postliste_${{ github.event.inputs.year }}_H1.json src/config/config_fullscrape.json
          git commit -m "Fullscrape ${{ github.event.inputs.year }} H1" || echo "Ingen endringer å committe"

          git stash --include-untracked || true
          git pull --rebase --autostash origin main || true
          git stash pop || true

          for i in {1..5}; do
            git push origin main && break
            echo "Push feilet, prøver igjen ($i/5)..."
            git pull --rebase --autostash origin main || true
          done


  scrape_H2:
    runs-on: ubuntu-latest
    needs: scrape_H1

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          ref: main

      - name: Kjør H2-scrape
        working-directory: src/scrapers
        run: |
          echo "=== STARTER FULLSCRAPE H2 ==="
          python scraper_dates.py \
            --config ../config/config_fullscrape.json \
            "${{ github.event.inputs.h2_start }}" \
            "${{ github.event.inputs.h2_end }}"

      - name: Arkiver H2-resultat
        run: |
          mkdir -p data/archive
          cp data/postliste.json \
            "data/archive/postliste_${{ github.event.inputs.year }}_H2.json"

      - name: Commit og push H2
        run: |
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          git add data/archive/postliste_${{ github.event.inputs.year }}_H2.json src/config/config_fullscrape.json
          git commit -m "Fullscrape ${{ github.event.inputs.year }} H2" || echo "Ingen endringer å committe"

          git stash --include-untracked || true
          git pull --rebase --autostash origin main || true
          git stash pop || true

          for i in {1..5}; do
            git push origin main && break
            echo "Push feilet, prøver igjen ($i/5)..."
            git pull --rebase --autostash origin main || true
          done
