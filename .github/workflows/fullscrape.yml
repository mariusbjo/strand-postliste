name: Full historical scrape

on:
  workflow_dispatch:
    inputs:
      year:
        description: "Årstall for fullscrape (f.eks. 2009)"
        required: true
        type: string

      start_page:
        description: "Start page (f.eks. 3475)"
        required: true
        type: string

      max_pages:
        description: "Max pages (f.eks. 3505)"
        required: true
        type: string

      h1_start:
        description: "Startdato H1 (DD.MM.YYYY)"
        required: true
        type: string

      h1_end:
        description: "Sluttdato H1 (DD.MM.YYYY)"
        required: true
        type: string

      h2_start:
        description: "Startdato H2 (DD.MM.YYYY)"
        required: true
        type: string

      h2_end:
        description: "Sluttdato H2 (DD.MM.YYYY)"
        required: true
        type: string

permissions:
  contents: write

concurrency:
  group: postliste-scraping
  cancel-in-progress: false

jobs:

  scrape_H1:
    runs-on: ubuntu-latest

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          ref: main

      - name: Sett opp Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Playwright cache
        uses: actions/cache@v4
        id: cache-playwright
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-v1

      - name: Installer Playwright + dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4
          playwright install chromium

      - name: Skriv config_fullscrape.json
        run: |
          mkdir -p src/config
          CONFIG_PATH="src/config/config_fullscrape.json"

          {
            echo "{"
            echo "  \"start_page\": ${{ github.event.inputs.start_page }},"
            echo "  \"max_pages\": ${{ github.event.inputs.max_pages }},"
            echo "  \"per_page\": 100"
            echo "}"
          } > $CONFIG_PATH

          echo "=== INNHOLD I config_fullscrape.json (H1) ==="
          cat $CONFIG_PATH

      - name: Kjør H1-scrape (FULL-modus)
        working-directory: src/scrapers
        run: |
          echo "=== STARTER FULLSCRAPE H1 ==="
          python scraper_dates.py \
            --mode full \
            --config ../config/config_fullscrape.json \
            "${{ github.event.inputs.h1_start }}" \
            "${{ github.event.inputs.h1_end }}"

      - name: Arkiver H1-resultat (kun filtrerte data)
        run: |
          mkdir -p data/archive
          cp data/postliste_filtered.json \
            "data/archive/postliste_${{ github.event.inputs.year }}_H1.json"

      - name: Commit og push H1
        run: |
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          git add data/archive/postliste_${{ github.event.inputs.year }}_H1.json src/config/config_fullscrape.json
          git commit -m "Fullscrape ${{ github.event.inputs.year }} H1" || echo "Ingen endringer å committe"

          git stash --include-untracked || true
          git pull --rebase --autostash origin main || true
          git stash pop || true

          for i in {1..5}; do
            git push origin main && break
            echo "Push feilet, prøver igjen ($i/5)..."
            git pull --rebase --autostash origin main || true
          done


  scrape_H2:
    runs-on: ubuntu-latest
    needs: scrape_H1

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          ref: main

      - name: Sett opp Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Playwright cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-v1

      - name: Installer Playwright + dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4
          playwright install chromium

      - name: Skriv config_fullscrape.json (H2)
        run: |
          mkdir -p src/config
          CONFIG_PATH="src/config/config_fullscrape.json"

          {
            echo "{"
            echo "  \"start_page\": ${{ github.event.inputs.start_page }},"
            echo "  \"max_pages\": ${{ github.event.inputs.max_pages }},"
            echo "  \"per_page\": 100"
            echo "}"
          } > $CONFIG_PATH

          echo "=== INNHOLD I config_fullscrape.json (H2) ==="
          cat $CONFIG_PATH

      - name: Kjør H2-scrape (FULL-modus)
        working-directory: src/scrapers
        run: |
          echo "=== STARTER FULLSCRAPE H2 ==="
          python scraper_dates.py \
            --mode full \
            --config ../config/config_fullscrape.json \
            "${{ github.event.inputs.h2_start }}" \
            "${{ github.event.inputs.h2_end }}"

      - name: Arkiver H2-resultat (kun filtrerte data)
        run: |
          mkdir -p data/archive
          cp data/postliste_filtered.json \
            "data/archive/postliste_${{ github.event.inputs.year }}_H2.json"

      - name: Commit og push H2
        run: |
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          git add data/archive/postliste_${{ github.event.inputs.year }}_H2.json src/config/config_fullscrape.json
          git commit -m "Fullscrape ${{ github.event.inputs.year }} H2" || echo "Ingen endringer å committe"

          git stash --include-untracked || true
          git pull --rebase --autostash origin main || true
          git stash pop || true

          for i in {1..5}; do
            git push origin main && break
            echo "Push feilet, prøver igjen ($i/5)..."
            git pull --rebase --autostash origin main || true
          done
