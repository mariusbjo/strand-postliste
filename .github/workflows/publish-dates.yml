name: Publish-dates-scraping

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: "Startdato (YYYY-MM-DD)"
        required: true
      end_date:
        description: "Sluttdato (YYYY-MM-DD)"
        required: false
      start_page:
        description: "Start side"
        required: false
        default: "1"
      max_pages:
        description: "Maks sider"
        required: false
        default: "100"

permissions:
  contents: write

concurrency:
  group: postliste-publish-dates
  cancel-in-progress: false

jobs:
  scrape_dates:
    runs-on: ubuntu-latest

    steps:
      - name: Sjekk ut repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Sett opp Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Playwright cache
        uses: actions/cache@v4
        id: cache-playwright
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-v1

      - name: Installer Playwright + dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4
          playwright install chromium

      # --- AUTOMATISK MIGRERING HVIS LEGACY-FIL FINNES ---
      - name: Migrer postliste.json til shards (hvis nødvendig)
        run: |
          if [ -f data/postliste.json ]; then
            echo "[INFO] Legacy postliste.json funnet – migrerer til shards..."
            python tools/migrate_postliste_json_to_shards.py
          else
            echo "[INFO] Ingen legacy postliste.json – hopper over migrering."
          fi

      - name: Skriv config_dates.json basert på input
        run: |
          mkdir -p src/config
          {
            echo "{"
            echo "  \"start_page\": ${{ github.event.inputs.start_page }},"
            echo "  \"max_pages\": ${{ github.event.inputs.max_pages }},"
            echo "  \"per_page\": 100"
            echo "}"
          } > src/config/config_dates.json

          echo "=== INNHOLD I config_dates.json ==="
          cat src/config/config_dates.json

      - name: Kjør scraper_dates.py (PUBLISH-modus)
        working-directory: src/scrapers
        run: |
          echo "=== STARTER SCRAPER (publish-dates) ==="
          python scraper_dates.py \
            --mode publish \
            --config ../config/config_dates.json \
            "${{ github.event.inputs.start_date }}" \
            "${{ github.event.inputs.end_date }}"

      # --- GIT REMOTE ---
      - name: Sett opp git remote
        run: |
          git remote remove origin || true
          git remote add origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git
          git remote -v

      # --- COMMIT & PUSH ---
      - name: Commit og push oppdateringer (konkurransesikker)
        run: |
          git config --global user.name "${{ github.actor }}"
          git config --global user.email "${{ github.actor }}@users.noreply.github.com"

          echo "=== Endringer i data/ ==="
          git status data/

          # Shard-filer
          git add data/postliste_*.json || true
          git add data/postliste_index.json || true

          # Endringslogg
          git add data/changes.json || true

          # Slett legacy hvis den fortsatt finnes
          git rm data/postliste.json || true

          git commit -m "Oppdatert postliste via publish-dates workflow (sharded)" || echo "Ingen endringer å committe"

          git stash --include-untracked || true
          git pull --rebase --autostash origin main || true
          git stash pop || true

          for i in {1..5}; do
            git push origin main && break
            echo "Push feilet, prøver igjen ($i/5)..."
            git pull --rebase --autostash origin main || true
          done
